<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | CS, Georgia Tech | Fall 2019: CS 6476</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Sketch-Based Image Retrieval</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Ramya Sree Boppana (903456349), Ang Deng (902989694), and Sanjana Garg (903475801)</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2019: CS 6476 Computer Vision: Class Project</span><br>Georgia Tech</span>
<hr>


<!-- Introduction -->
<h3>Problem statement</h3>
In this project, we aim to retrieve images from a database using a sketch. Our motivation for the problem arises from the limitation of traditional text-based image search methods. These methods can no longer suffice to help people find specifically the image they wanted as the database of images grows larger and larger and accurately detailed tagging of images becomes unrealistic. Also, with the increasing use of touch screen devices, this has relevant applications in e-commerce platforms. Sketches have a much greater potential to describe the content and exact details of the image than plain text and are a more direct way of expressing human thoughts than text abstraction. Using sketch to retrieve images also alleviates the need for generating accurate captions for existing images, which becomes a complex natural language processing problem as the description is required to be more specific and detailed. The user can sketch either the entire scene or just the object. For our project, we are focusing on using just object sketches for image retrieval.
<br> We aim to build a system that takes a sketch image file as input and retrieves top k similar images from the database as output.
<br> To achieve our goal, we will apply techniques that we have learned in class as well as knowledge gained from current literature in the field.


<br><br>
<!-- Approach -->
<h3>Approach</h3>
Describe very clearly and systematically your approach to solve the problem. Tell us exactly what existing implementations you used to build your system. Tell us what obstacles you faced and how you addressed them. Justify any design choices or judgment calls you made in your approach.
<!-- Approach Figure --> 
<div style="text-align: center;">
<img style="height: 250px;" alt="" src="proposal_approach_flow_diagram.png">
</div>

<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
<h4>Datasets</h4>
<b>The Sketchy Database</b> <a href="http://sketchy.eye.gatech.edu/explore/banana.html">http://sketchy.eye.gatech.edu/explore/banana.html</a>
<br><b>Shoe</b>  <a href="https://www.eecs.qmul.ac.uk/~qian/Project_cvpr16.html">https://www.eecs.qmul.ac.uk/~qian/Project_cvpr16.html</a>
<br>
<br>We first start with the two category dataset Shoe for our problem, to test our features and then experiment with the Sketchy database which has more number of categories. 

<br>For our implementation, we will be using existing libraries in Python like OpenCV for edge detection, feature extraction and scipy for similarity metrics computation. We will build a pipeline for the pre-processing and retrieval phases mentioned above. The success of our project would be if the user is able to retrieve similar images given a sketch image. We will be using the following evaluation metrics for measuring the performance of our system:
<br>   - Precision at K
<br>   - Recall at K

<br>The datasets we are using are designed for fine-grained sketch-based image retrieval that is used to embed images and sketches in the same feature space using convolutional networks. However, we intend to use traditional techniques in computer vision for constructing our feature representations which makes us uncertain about how these hand-crafted features would perform on the dataset.

<br><br>

<h4>References/Citations</h4>
add proper references/citations to any existing code that you might use (e.g. links to GitHub repos etc.).
<br>[1] Li, Y. & Li, W. Machine Vision and Applications (2018) 29: 1083. https://doi.org/10.1007/s00138-018-0953-8
<br>[2] M. Eitz, K. Hildebrand, T. Boubekeur and M. Alexa, "Sketch-Based Image Retrieval: Benchmark and Bag-of-Features Descriptors," in IEEE Transactions on Visualization and Computer Graphics, vol. 17, no. 11, pp. 1624-1636, Nov. 2011.
<br>[3] Xiao, Changcheng & Wang, Changhu & Zhang, Liqing & Zhang, Lei. (2015). Sketch-based Image Retrieval via Shape Words. 571-574. 10.1145/2671188.2749360. 
<br>[4] C. Xiao, C. Wang, L. Zhang, and L. Zhang, “IdeaPanel,” in Proceedings of the 5th ACM on International Conference on Multimedia Retrieval-ICMR '15, pp. 667-668 (2015).

<br><br>

  <hr>
  <footer> 
  <p>© Ramya Sree Boppana, Ang Deng, and Sanjana Garg </p>
  </footer>
</div>
</div>

<br><br>

</body></html>